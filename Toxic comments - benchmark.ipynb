{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test = test.drop(test.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate          clean  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data by class\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train['clean'] = 1-train[list_classes].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words using ngrams\n",
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering, using tf-idf\n",
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "all_comments = pd.concat([train['comment_text'], test['comment_text']])\n",
    "vec.fit(all_comments)\n",
    "trn_term_doc = vec.transform(train['comment_text'])\n",
    "test_term_doc = vec.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes equation\n",
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "test accuracy : 0.9302241956161471\n",
      "fit severe_toxic\n",
      "test accuracy : 0.9905881617210218\n",
      "fit obscene\n",
      "test accuracy : 0.9627747725211845\n",
      "fit threat\n",
      "test accuracy : 0.9968887777117663\n",
      "fit insult\n",
      "test accuracy : 0.9608673900128201\n",
      "fit identity_hate\n",
      "test accuracy : 0.9904005503267566\n"
     ]
    }
   ],
   "source": [
    "# for each label\n",
    "preds = np.zeros((len(test), len(list_classes)))\n",
    "\n",
    "for i, j in enumerate(list_classes):\n",
    "    print('fit', j)\n",
    "    train_y = train[j].values\n",
    "    test_y = test[j].values\n",
    "    r = np.log(pr(1,train_y) / pr(0,train_y))\n",
    "    svm = LinearSVC(C=4, dual=False)\n",
    "    train_x_nb = x.multiply(r)\n",
    "    svm.fit(train_x_nb, train_y)\n",
    "    preds[:,i] = svm.predict(test_x.multiply(r))\n",
    "    print(\"test accuracy :\", svm.score(test_x.multiply(r), test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63962\n",
      "\n",
      "toxic\n",
      "roc auc score  0.8617727487074569\n",
      "accuracy  0.9302241956161471\n",
      "precision score  0.9404145369963793\n",
      "recall score  0.9302241956161471\n",
      "f1 score  0.9340753064325905\n",
      "\n",
      "severe_toxic\n",
      "roc auc score  0.6502694433474697\n",
      "accuracy  0.9905881617210218\n",
      "precision score  0.9916940848522624\n",
      "recall score  0.9905881617210218\n",
      "f1 score  0.9911202217202197\n",
      "\n",
      "obscene\n",
      "roc auc score  0.8352773104413922\n",
      "accuracy  0.9627747725211845\n",
      "precision score  0.9632718634781431\n",
      "recall score  0.9627747725211845\n",
      "f1 score  0.9630151866745618\n",
      "\n",
      "threat\n",
      "roc auc score  0.6630600571937874\n",
      "accuracy  0.9968887777117663\n",
      "precision score  0.9962905584145378\n",
      "recall score  0.9968887777117663\n",
      "f1 score  0.9964974492500596\n",
      "\n",
      "insult\n",
      "roc auc score  0.7597236272853106\n",
      "accuracy  0.9608673900128201\n",
      "precision score  0.9575920338493626\n",
      "recall score  0.9608673900128201\n",
      "f1 score  0.9588027262441966\n",
      "\n",
      "identity_hate\n",
      "roc auc score  0.6674167961984279\n",
      "accuracy  0.9904005503267566\n",
      "precision score  0.9885209916813351\n",
      "recall score  0.9904005503267566\n",
      "f1 score  0.988965224147873\n",
      "\n",
      "Overall\n",
      "roc auc score  0.7395866638623074\n",
      "accuracy  0.8813045245614584\n",
      "precision score  0.6276575337329509\n",
      "recall score  0.6578547763666482\n",
      "f1 score  0.6337277433800093\n"
     ]
    }
   ],
   "source": [
    "y_test = test.iloc[:, 2:]\n",
    "\n",
    "for l in range(len(list_classes)):\n",
    "    print(\"\\n\" + list_classes[l])\n",
    "    print(\"roc auc score \", metrics.roc_auc_score(y_test.iloc[:,l], preds[:,l]))\n",
    "    print(\"accuracy \", metrics.accuracy_score(y_test.iloc[:,l], np.round(preds[:,l]).astype(np.int)))\n",
    "    print(\"precision score \", metrics.precision_score(y_test.iloc[:,l], np.round(preds[:,l]).astype(np.int),  average='weighted'))\n",
    "    print(\"recall score \", metrics.recall_score(y_test.iloc[:,l], np.round(preds[:,l]).astype(np.int),  average='weighted'))\n",
    "    print(\"f1 score \", metrics.f1_score(y_test.iloc[:,l], np.round(preds[:,l]).astype(np.int), average='weighted'))\n",
    "\n",
    "print(\"\\n\" + \"Overall\")\n",
    "print(\"roc auc score \", metrics.roc_auc_score(y_test, preds))\n",
    "print(\"accuracy \", metrics.accuracy_score(y_test, np.round(preds).astype(np.int)))\n",
    "print(\"precision score \", metrics.precision_score(y_test, np.round(preds).astype(np.int),  average='weighted'))\n",
    "print(\"recall score \", metrics.recall_score(y_test, np.round(preds).astype(np.int),  average='weighted'))\n",
    "print(\"f1 score \", metrics.f1_score(y_test, np.round(preds).astype(np.int), average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
